DileptonEmission
=============================

The interface between hydrodynamic evolution and thermal dilepton emission, known as `DileptonEmission`, is adapted from a photon emission code available at [this GitHub repository](https://github.com/chunshen1987/photonEmission_hydroInterface). This adaptation allows for the seamless integration of thermal dilepton emission calculations with hydrodynamic simulations, providing a comprehensive framework for studying the emission of dileptons in heavy-ion collisions.

## Usage Instructions

### Performing a Simple Event

To run a simple event using this code, follow these steps:

1. **Clone and Compile the Code**

   Clone the code from the repository and compile it.

2. **Create a `parameters.dat` File**

   In the working directory of the code, create a file named `parameters.dat` to set up all the relevant parameters. Ensure this file contains the necessary configurations for your simulation.

3. **Create a `results/` Folder**

   In the working directory of the code, create a folder named `results/`. This is where the simulation results will be saved.

4. **Copy Hydrodynamic Evolution Data**

   Copy the hydrodynamic evolution file, `evolution_all_xyeta.dat` from `MUSIC`, and the hydro parameter file, `music_input`, into the `results/` folder. Make sure the code is set up to read an evolution file from a different hydrodynamic code in the required format if needed.

5. **Set the Number of Threads and Run the Simulation**

   Set the `OMP_NUM_THREADS` environment variable to specify the desired number of threads for parallel processing. For example:

   ```bash
   export OMP_NUM_THREADS=4
   ```
   
   Execute the simulation by running:
   
   ```
   ./dilepton_emission.e
   ```

That's it! Your simulation will run, and the results will be saved in the `results/` folder.

### Running Events on a Cluster

You can utilize the Python script `generate_jobs.py` to streamline the process of creating event folders, linking necessary files, generating parameter files, and submitting jobs to a Cluster. To run this script, you can simply execute the following command:

```
python ./generate_jobs.py AuAu 7.7 00 10 {suffix} parameters_dict_user.py
```

- `AuAu 7.7` specifies the collision system and the beam energy.
- `00` and `10` determine the centrality class.
- `{suffix}` is a customizable string that's added to the event folder name, resulting in a format like `AuAu7.7_00_10_{suffix}`.
- `parameters_dict_user.py` allows you to configure user-specific parameters.

Within the `config` folder, you'll find a file named `parameters_dict_master.py`, which contains all the default parameters you might need for reference and customization. This straightforward process enables you to efficiently generate event configurations and submit them to a Cluster for further processing.

**Important Note**: The current script expects specific directory structures within your home directory. Please ensure that alongside the working directory `dilepton`, you have an `iEBE-sampler` directory in the same home directory. This `iEBE-sampler` directory should contain the hydrodynamic events with names such as `AuAu7.7_00_10` and `AuAu19.6_70_80`. The script relies on these events for its operations.

#### Event Folder Generated by `generate_jobs.py`

Within the event folder, which has names such as `AuAu7.7_00_10_suffix`, you will find the following files and folders:

- `dilepton_emission.e`: A symbolic link to the `dilepton_emission.e` executable file in the working directory.
- `hdf5_zip_results.py`: A Python script used to compress all result files into an h5 file, named as `dilepton_results_AuAu7.7_00_10_suffix.h5`.
- `parameters_dict_user.py`: A copy of the Python script used to set user-specific parameters.
- `parameters.dat`: The parameter file, which is generated with a combination of user-specific parameters and default parameters.
- `ph_rates`: A symbolic link to the folder containing emission rates.
- `results`: The results folder housing result files and a symbolic link to the hydrodynamic evolution file.
- `submit_jobs.pbs`: A file used for job submission on a cluster.

The Slurm job script `submit_jobs.pbs` performs the following tasks:

- Configures job options using `#SBATCH` directives.
- Loads required modules.
- Sets the `OMP_NUM_THREADS` environment variable to define the desired number of threads for parallel processing.
- Executes the simulation.
- Compresses all result files into an h5 file.

#### Additional Utility Scripts

1. **Generate and Submit Jobs Script**
   - Generates event folders and submits jobs for different centrality classes at a given beam energy.
   - Usage: `sh generate_and_submit_all_centralities_jobs.sh 7.7 {suffix} parameters_dict_user.py`
2. **Download Results Script**
   - Downloads all result files for different centrality classes at a given beam energy.
   - Usage: `sh download_all_centralities_jobs.sh 7.7 {suffix}`
3. **Download Multiple Energies Script**
   - Loops the "Download Results Script" over selected beam energies.
   - Usage: `sh download_all_energies_jobs.sh`
   - The suffix needs to be specified in the script file.
